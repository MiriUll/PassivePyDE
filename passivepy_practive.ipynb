{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('Data/passivepy_humancoding_match.xlsx')\n",
    "df.drop(columns=['Unnamed: 0', 'PassiveMatch(es)', 'PassiveCount', 'match'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = r'C:\\Users\\mitra\\yelp_dataset\\yelp_academic_dataset_review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000000\n",
    "review = pd.read_json(FILE_PATH, lines=True,\n",
    "                      dtype={'review_id':str,'user_id':str,\n",
    "                             'business_id':str,'stars':int,\n",
    "                             'date':str,'text':str,'useful':int,\n",
    "                             'funny':int,'cool':int},\n",
    "                      chunksize=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 out of 1,000,000 related reviews\n",
      "1000000 out of 1,000,000 related reviews\n",
      "1000000 out of 1,000,000 related reviews\n",
      "1000000 out of 1,000,000 related reviews\n",
      "1000000 out of 1,000,000 related reviews\n",
      "1000000 out of 1,000,000 related reviews\n",
      "990280 out of 1,000,000 related reviews\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# There are multiple chunks to be read\n",
    "chunk_list = []\n",
    "\n",
    "for chunk_review in review:\n",
    "\n",
    "    # Drop columns that aren't needed\n",
    "    chunk_review = chunk_review.drop(['review_id','useful','funny','cool'], axis=1)\n",
    "    \n",
    "    # Show feedback on progress\n",
    "    print(f\"{chunk_review.shape[0]} out of {size:,} related reviews\")\n",
    "    chunk_list.append(chunk_review)\n",
    "    \n",
    "# After trimming down the review file, concatenate all relevant data back to one dataframe\n",
    "df = pd.concat(chunk_list, ignore_index=True, join='outer', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = r\"C:\\Users\\mitra\\yelp_dataset\\yelp_reviews_RV_categories.csv\"\n",
    "df.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>ID</th>\n",
       "      <th>Test</th>\n",
       "      <th>Cond</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_coding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>934</td>\n",
       "      <td>934</td>\n",
       "      <td>929</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence   ID  Test  Cond\n",
       "human_coding                           \n",
       "0                  934  934   929   934\n",
       "1                  216  216   216   216"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('human_coding').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adfccd5c958d70cd78f22c942a5f90dd259f52bf203482d766a0ca6ec5e2e798"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
